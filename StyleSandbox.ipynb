{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleSandbox",
      "provenance": [],
      "authorship_tag": "ABX9TyNGR3nGZCa9fyKD9o7s/xgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balcomes/keras-autoencoders/blob/master/StyleSandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ21cHx-koz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "import time\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "\n",
        "target_image_path = 'sprite.png'\n",
        "style_reference_image_path = 'dwarves.png'\n",
        "width, height = load_img(target_image_path).size\n",
        "img_height = 400\n",
        "img_width = int(width * img_height / height)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "  img = load_img(image_path, target_size=(img_height, img_width))\n",
        "  img = img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = vgg19.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def deprocess_image(x):\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "  x = x[:, :, ::-1]\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x\n",
        "\n",
        "target_image = K.constant(preprocess_image(target_image_path))\n",
        "style_reference_image = K.constant(preprocess_image(style_reference_image_path))\n",
        "combination_image = K.placeholder((1, img_height, img_width, 3))\n",
        "\n",
        "input_tensor = K.concatenate([target_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)\n",
        "\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet',\n",
        "                    include_top=False)\n",
        "\n",
        "print('Model loaded.')\n",
        "\n",
        "def content_loss(base, combination):\n",
        "  return K.sum(K.square(combination - base))\n",
        "\n",
        "def gram_matrix(x):\n",
        "  features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "  gram = K.dot(features, K.transpose(features))\n",
        "  return gram\n",
        "\n",
        "def style_loss(style, combination):\n",
        "  S = gram_matrix(style)\n",
        "  C = gram_matrix(combination)\n",
        "  channels = 3\n",
        "  size = img_height * img_width\n",
        "  return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "def total_variation_loss(x):\n",
        "  a = K.square(x[:,:img_height-1,:img_width-1,:] - x[:,1:,:img_width-1,:])\n",
        "  b = K.square(x[:,:img_height-1,:img_width-1,:] - x[:,:img_height-1,1:,:])\n",
        "  return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "content_layer = 'block5_conv2'\n",
        "\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1',\n",
        "                'block4_conv1',\n",
        "                'block5_conv1']\n",
        "\n",
        "total_variation_weight = 1e-4\n",
        "style_weight = 1.\n",
        "content_weight = 0.025\n",
        "loss = K.variable(0.)\n",
        "layer_features = outputs_dict[content_layer]\n",
        "target_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "\n",
        "loss += content_weight * content_loss(target_image_features,\n",
        "                                      combination_features)\n",
        "\n",
        "for layer_name in style_layers:\n",
        "  layer_features = outputs_dict[layer_name]\n",
        "  style_reference_features = layer_features[1, :, :, :]\n",
        "  combination_features = layer_features[2, :, :, :]\n",
        "  sl = style_loss(style_reference_features, combination_features)\n",
        "  loss += (style_weight / len(style_layers)) * sl\n",
        "\n",
        "loss += total_variation_weight * total_variation_loss(combination_image)\n",
        "\n",
        "grads = K.gradients(loss, combination_image)[0]\n",
        "fetch_loss_and_grads = K.function([combination_image], [loss, grads])\n",
        "\n",
        "class Evaluator(object):\n",
        "  def __init__(self):\n",
        "    self.loss_value = None\n",
        "    self.grads_values = None\n",
        "\n",
        "  def loss(self, x):\n",
        "    assert self.loss_value is None\n",
        "    x = x.reshape((1, img_height, img_width, 3))\n",
        "    outs = fetch_loss_and_grads([x])\n",
        "    loss_value = outs[0]\n",
        "    grad_values = outs[1].flatten().astype('float64')\n",
        "    self.loss_value = loss_value\n",
        "    self.grad_values = grad_values\n",
        "    return self.loss_value\n",
        "\n",
        "  def grads(self, x):\n",
        "    assert self.loss_value is not None\n",
        "    grad_values = np.copy(self.grad_values)\n",
        "    self.loss_value = None\n",
        "    self.grad_values = None\n",
        "    return grad_values\n",
        "\n",
        "evaluator = Evaluator()\n",
        "\n",
        "result_prefix = 'my_result'\n",
        "iterations = 20\n",
        "x = preprocess_image(target_image_path)\n",
        "x = x.flatten()\n",
        "\n",
        "for i in range(iterations):\n",
        "  print('Start of iteration', i)\n",
        "  start_time = time.time()\n",
        "  x, min_val, info = fmin_l_bfgs_b(evaluator.loss,\n",
        "                                   x,\n",
        "                                   fprime=evaluator.grads,\n",
        "                                   maxfun=20)\n",
        "  print('Current loss value:', min_val)\n",
        "  img = x.copy().reshape((img_height, img_width, 3))\n",
        "  img = deprocess_image(img)\n",
        "  fname = result_prefix + '_at_iteration_%d.png' % i\n",
        "  imageio.imwrite(fname, img)\n",
        "  print('Image saved as', fname)\n",
        "  end_time = time.time()\n",
        "  print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I644MDo87hyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "#z_mean, z_log_variance = encoder(input_img)\n",
        "#z = z_mean + exp(z_log_variance) * epsilon\n",
        "#reconstructed_img = decoder(z)\n",
        "#model = Model(input_img, reconstructed_img)\n",
        "\n",
        "img_shape = (28, 28, 1)\n",
        "batch_size = 16\n",
        "latent_dim = 2\n",
        "input_img = keras.Input(shape=img_shape)\n",
        "\n",
        "x = layers.Conv2D(32, 3, padding='same',\n",
        "                  activation='relu')(input_img)\n",
        "x = layers.Conv2D(64, 3, padding='same',\n",
        "                  activation='relu', strides=(2, 2))(x)\n",
        "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "  epsilon = K.random_normal(shape=(K.shape(z_mean)[0],\n",
        "                                   latent_dim), mean=0., stddev=1.)\n",
        "  return z_mean + K.exp(z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
        "\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]),\n",
        "                 activation='relu')(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "x = layers.Conv2DTranspose(32, 3,\n",
        "                           padding='same',\n",
        "                           activation='relu',\n",
        "                           strides=(2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "decoder = Model(decoder_input, x)\n",
        "z_decoded = decoder(z)\n",
        "\n",
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "  def vae_loss(self, x, z_decoded):\n",
        "    x = K.flatten(x)\n",
        "    z_decoded = K.flatten(z_decoded)\n",
        "    xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "    kl_loss = -5e-4 * K.mean(\n",
        "    1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs[0]\n",
        "    z_decoded = inputs[1]\n",
        "    loss = self.vae_loss(x, z_decoded)\n",
        "    self.add_loss(loss, inputs=inputs)\n",
        "    return x\n",
        "\n",
        "y = CustomVariationalLayer()([input_img, z_decoded])\n",
        "\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer='rmsprop', loss=None)\n",
        "vae.summary()\n",
        "\n",
        "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "vae.fit(x=x_train,\n",
        "        y=None,\n",
        "        shuffle=True,\n",
        "        epochs=10,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, None))\n",
        "\n",
        "n = 15\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "  for j, xi in enumerate(grid_y):\n",
        "    z_sample = np.array([[xi, yi]])\n",
        "    z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
        "    x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
        "    digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "    figure[i * digit_size: (i + 1) * digit_size,\n",
        "           j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJI1X3o19A5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "from keras import layers\n",
        "from keras.preprocessing import image\n",
        "\n",
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()\n",
        "\n",
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008,\n",
        "                                                   clipvalue=1.0,\n",
        "                                                   decay=1e-8)\n",
        "\n",
        "discriminator.compile(optimizer=discriminator_optimizer,\n",
        "                      loss='binary_crossentropy')\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
        "\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = x_train[y_train.flatten() == 6]\n",
        "x_train = x_train.reshape((x_train.shape[0],) +\n",
        "                          (height, width, channels)).astype('float32') / 255.\n",
        "\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = ''\n",
        "start = 0\n",
        "\n",
        "for step in range(iterations):\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "  stop = start + batch_size\n",
        "  real_images = x_train[start: stop]\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)),\n",
        "                           np.zeros((batch_size, 1))])\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "  start += batch_size\n",
        "\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "\n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('adversarial loss:', a_loss)\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k30EfIZofIp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3a84ffa-78a4-45ca-f8b2-2fe48738430e"
      },
      "source": [
        "import autogluon as ag\n",
        "from autogluon import TabularPrediction as task\n",
        "\n",
        "train_data = task.Dataset(file_path =\n",
        "              'https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
        "\n",
        "# subsample 500 data points for faster demo\n",
        "train_data = train_data.head(500)\n",
        "print(train_data.head())\n",
        "\n",
        "label_column = 'class'\n",
        "print(\"Summary of class variable: \\n\", train_data[label_column].describe())\n",
        "\n",
        "dir = 'agModels-predictClass'\n",
        "\n",
        "# specifies folder where to store trained models\n",
        "predictor = task.fit(train_data = train_data,\n",
        "                     label = label_column,\n",
        "                     output_directory = dir)\n",
        "\n",
        "test_data = task.Dataset(file_path =\n",
        "              'https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
        "\n",
        "# values to predict\n",
        "y_test = test_data[label_column]\n",
        "\n",
        "# delete label column to prove we're not cheating\n",
        "test_data_nolab = test_data.drop(labels = [label_column], axis = 1)\n",
        "print(test_data_nolab.head())\n",
        "\n",
        "# unnecessary, just demonstrates how to load\n",
        "# previously-trained predictor from file\n",
        "\n",
        "#predictor = task.load(dir) \n",
        "\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "print(\"Predictions:  \", y_pred)\n",
        "perf = predictor.evaluate_predictions(y_true = y_test,\n",
        "                                      y_pred = y_pred,\n",
        "                                      auxiliary_metrics = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to agModels-predictClass/\n",
            "Train Data Rows:    500\n",
            "Train Data Columns: 15\n",
            "Preprocessing data ...\n",
            "Here are the first 10 unique label values in your data:  [' <=50K' ' >50K']\n",
            "AutoGluon infers your prediction problem is: binary  (because only two unique label-values observed)\n",
            "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "Feature Generator processed 500 data points with 14 features\n",
            "Original Features:\n",
            "\tint features: 6\n",
            "\tobject features: 8\n",
            "Generated Features:\n",
            "\tint features: 0\n",
            "All Features:\n",
            "\tint features: 6\n",
            "\tobject features: 8\n",
            "\tData preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
            "To change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: accuracy\n",
            "Fitting model: RandomForestClassifierGini ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   age   workclass  fnlwgt  ... hours-per-week  native-country   class\n",
            "0   25     Private  178478  ...             40   United-States   <=50K\n",
            "1   23   State-gov   61743  ...             35   United-States   <=50K\n",
            "2   46     Private  376789  ...             15   United-States   <=50K\n",
            "3   55           ?  200235  ...             50   United-States    >50K\n",
            "4   36     Private  224541  ...             40     El-Salvador   <=50K\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "Summary of class variable: \n",
            " count        500\n",
            "unique         2\n",
            "top        <=50K\n",
            "freq         394\n",
            "Name: class, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t0.89\t = Validation accuracy score\n",
            "\t0.65s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestClassifierEntr ...\n",
            "\t0.9\t = Validation accuracy score\n",
            "\t0.64s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesClassifierGini ...\n",
            "\t0.86\t = Validation accuracy score\n",
            "\t0.53s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: ExtraTreesClassifierEntr ...\n",
            "\t0.86\t = Validation accuracy score\n",
            "\t0.52s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsClassifierUnif ...\n",
            "\t0.8\t = Validation accuracy score\n",
            "\t0.01s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsClassifierDist ...\n",
            "\t0.77\t = Validation accuracy score\n",
            "\t0.02s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifier ...\n",
            "\t0.88\t = Validation accuracy score\n",
            "\t0.34s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: CatboostClassifier ...\n",
            "\t0.9\t = Validation accuracy score\n",
            "\t0.87s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetClassifier ...\n",
            "\t0.88\t = Validation accuracy score\n",
            "\t14.87s\t = Training runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifierCustom ...\n",
            "\t0.89\t = Validation accuracy score\n",
            "\t0.51s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: weighted_ensemble_k0_l1 ...\n",
            "\t0.91\t = Validation accuracy score\n",
            "\t0.55s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 21.75s ...\n",
            "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   age          workclass  fnlwgt  ... capital-loss  hours-per-week  native-country\n",
            "0   31            Private  169085  ...            0              20   United-States\n",
            "1   17   Self-emp-not-inc  226203  ...            0              45   United-States\n",
            "2   47            Private   54260  ...         1887              60   United-States\n",
            "3   21            Private  176262  ...            0              30   United-States\n",
            "4   17            Private  241185  ...            0              20   United-States\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation: accuracy on test data: 0.825366\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictions:   [' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' <=50K']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.8253659535264612,\n",
            "    \"accuracy_score\": 0.8253659535264612,\n",
            "    \"balanced_accuracy_score\": 0.6880318396555511,\n",
            "    \"matthews_corrcoef\": 0.46129936504568697,\n",
            "    \"f1_score\": 0.8253659535264612\n",
            "}\n",
            "Detailed (per-class) classification report:\n",
            "{\n",
            "    \" <=50K\": {\n",
            "        \"precision\": 0.8418421992145663,\n",
            "        \"recall\": 0.9494027647295665,\n",
            "        \"f1-score\": 0.892393086918128,\n",
            "        \"support\": 7451\n",
            "    },\n",
            "    \" >50K\": {\n",
            "        \"precision\": 0.7240117130307467,\n",
            "        \"recall\": 0.4266609145815358,\n",
            "        \"f1-score\": 0.5369163952225842,\n",
            "        \"support\": 2318\n",
            "    },\n",
            "    \"accuracy\": 0.8253659535264612,\n",
            "    \"macro avg\": {\n",
            "        \"precision\": 0.7829269561226565,\n",
            "        \"recall\": 0.6880318396555511,\n",
            "        \"f1-score\": 0.7146547410703561,\n",
            "        \"support\": 9769\n",
            "    },\n",
            "    \"weighted avg\": {\n",
            "        \"precision\": 0.8138832405725258,\n",
            "        \"recall\": 0.8253659535264612,\n",
            "        \"f1-score\": 0.8080451524979959,\n",
            "        \"support\": 9769\n",
            "    }\n",
            "}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcgdwHJ1h7LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = task.fit(train_data = task.Dataset(file_path = <file-name>),\n",
        "                     label_column = <variable-name>)\n",
        "\n",
        "results = predictor.fit_summary()\n",
        "\n",
        "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
        "print(\"AutoGluon categorized the features as: \", predictor.feature_types)\n",
        "\n",
        "age_column = 'age'\n",
        "print(\"Summary of age variable: \\n\", train_data[age_column].describe())\n",
        "\n",
        "predictor_age = task.fit(train_data = train_data,\n",
        "                         output_directory = \"agModels-predictAge\",\n",
        "                         label = age_column)\n",
        "\n",
        "performance = predictor_age.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbIuyf3oCS9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install imageio\n",
        "#!pip install --upgrade mxnet\n",
        "#!pip install autogluon\n",
        "\n",
        "#!pip install distributed==1.23.3\n",
        "#!pip install dask==0.19.4\n",
        "#!pip install tornado==4.5.1\n",
        "\n",
        "#WARNING: Upgrading ipython, ipykernel, tornado, prompt-toolkit or pyzmq can\n",
        "#cause your runtime to repeatedly crash or behave in unexpected ways and is not\n",
        "#recommended. If your runtime won't connect or execute code, you can reset it\n",
        "#with \"Factory reset runtime\" from the \"Runtime\" menu.\n",
        "#WARNING: tornado > 4.5.0 is incompatible with ipykernel < 5.0\n",
        "#WARNING: The following packages were previously imported in this runtime:\n",
        "#  [PIL,tornado,tqdm]\n",
        "#Run \"pip install -U ipykernel\" before restarting to avoid repeated crashes."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}