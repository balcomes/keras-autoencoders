{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNO5mhHfDaJBLEqqF/+wYxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balcomes/keras-autoencoders/blob/master/train_conv_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-yrQggzeim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "fd5add2b-ff54-4782-816a-4cc017a45ca7"
      },
      "source": [
        "# USAGE\n",
        "# python train_conv_autoencoder.py\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from pyimagesearch.convautoencoder import ConvAutoencoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-s\", \"--samples\", type=int, default=8,\n",
        "\thelp=\"# number of samples to visualize when decoding\")\n",
        "ap.add_argument(\"-o\", \"--output\", type=str, default=\"output.png\",\n",
        "\thelp=\"path to output visualization file\")\n",
        "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
        "\thelp=\"path to output plot file\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# initialize the number of epochs to train for and batch size\n",
        "EPOCHS = 25\n",
        "BS = 32\n",
        "\n",
        "# load the MNIST dataset\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "((trainX, _), (testX, _)) = mnist.load_data()\n",
        "\n",
        "# add a channel dimension to every image in the dataset, then scale\n",
        "# the pixel intensities to the range [0, 1]\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "# construct our convolutional autoencoder\n",
        "print(\"[INFO] building autoencoder...\")\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(lr=1e-3)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "\ttrainX, trainX,\n",
        "\tvalidation_data=(testX, testX),\n",
        "\tepochs=EPOCHS,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "# construct a plot that plots and saves the training history\n",
        "N = np.arange(0, EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(args[\"plot\"])\n",
        "\n",
        "# use the convolutional autoencoder to make predictions on the\n",
        "# testing images, then initialize our list of output images\n",
        "print(\"[INFO] making predictions...\")\n",
        "decoded = autoencoder.predict(testX)\n",
        "outputs = None\n",
        "\n",
        "# loop over our number of output samples\n",
        "for i in range(0, args[\"samples\"]):\n",
        "\t# grab the original image and reconstructed image\n",
        "\toriginal = (testX[i] * 255).astype(\"uint8\")\n",
        "\trecon = (decoded[i] * 255).astype(\"uint8\")\n",
        "\n",
        "\t# stack the original and reconstructed image side-by-side\n",
        "\toutput = np.hstack([original, recon])\n",
        "\n",
        "\t# if the outputs array is empty, initialize it as the current\n",
        "\t# side-by-side image display\n",
        "\tif outputs is None:\n",
        "\t\toutputs = output\n",
        "\n",
        "\t# otherwise, vertically stack the outputs\n",
        "\telse:\n",
        "\t\toutputs = np.vstack([outputs, output])\n",
        "\n",
        "# save the outputs image to disk\n",
        "cv2.imwrite(args[\"output\"], outputs)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f58fde82b469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# import the necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyimagesearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvautoencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyimagesearch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVF1eeL4znmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}